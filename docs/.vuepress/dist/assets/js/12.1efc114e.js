(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{374:function(e,t,a){"use strict";a.r(t);var r=a(25),s=Object(r.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"⚡️-technologies"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#⚡️-technologies"}},[e._v("#")]),e._v(" ⚡️ Technologies")]),e._v(" "),a("p",[e._v("For bringing Shortify to life, we have used following tech:")]),e._v(" "),a("ul",[a("li",[e._v("React.js for frontend development")]),e._v(" "),a("li",[e._v("Flask for backend development")]),e._v(" "),a("li",[e._v("BERT Model for Natural Language Processing (NLP)")])]),e._v(" "),a("h2",{attrs:{id:"react-js"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#react-js"}},[e._v("#")]),e._v(" React.js")]),e._v(" "),a("p",[e._v("React.js is a JavaScript "),a("strong",[e._v("frontend")]),e._v(" library developed by the folks at Facebook Inc. For writing the code, we made use of the following React.js practices:")]),e._v(" "),a("ul",[a("li",[e._v("Controlled Components for state management")]),e._v(" "),a("li",[e._v("Functional Components (Recommended by Facebook)")]),e._v(" "),a("li",[e._v("React.js hooks for making API requests and dealing with the state")])]),e._v(" "),a("h2",{attrs:{id:"flask"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flask"}},[e._v("#")]),e._v(" Flask")]),e._v(" "),a("p",[e._v("We chose to work with Flask because of the "),a("strong",[e._v("NLP model")]),e._v(" we used was written in python. The overall architecture is as simple as it gets. To make the clientside and backend talk, we wrote a route that was taking the content or the URL from the frontend and then sending the summarize content as response.")]),e._v(" "),a("h2",{attrs:{id:"bert-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bert-model"}},[e._v("#")]),e._v(" BERT Model")]),e._v(" "),a("p",[e._v("In this project we're using an NLP model (BERT). This model utilizes the HuggingFace Pytorch transformers library to run extractive summarizations. This works by first embedding the sentences, then running a clustering algorithm, finding the sentences that are closest to the cluster's centroids. This library also uses coreference techniques, utilizing the "),a("a",{attrs:{href:"https://github.com/huggingface/neuralcoref",target:"_blank",rel:"noopener noreferrer"}},[e._v("Neural Coref"),a("OutboundLink")],1),e._v(" library to resolve words in summaries that need more context.")])])}),[],!1,null,null,null);t.default=s.exports}}]);